{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05fcf9e-a9e6-460e-89bb-cbba2eb04374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities:\n",
      "buys_computer\n",
      "yes    0.642857\n",
      "no     0.357143\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A1\n",
    "import pandas as pd\n",
    "\n",
    "# Data from CSV file\n",
    "df = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count instances for each class\n",
    "class_counts = df['buys_computer'].value_counts()\n",
    "\n",
    "# Calculating prior probabilities\n",
    "total_instances = len(df)\n",
    "prior_probabilities = class_counts / total_instances\n",
    "\n",
    "# Results\n",
    "print(\"Prior Probabilities:\")\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f514309d-f4cb-4a82-82d5-edc7a4012e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: no, Feature: age_31...40, Density: [-0.22579135 -0.22579135 -2.22579135 -0.22579135 -0.22579135 -0.22579135\n",
      " -2.22579135 -0.22579135 -0.22579135 -0.22579135 -0.22579135 -2.22579135\n",
      " -2.22579135 -0.22579135]\n",
      "Class: no, Feature: age_<=30, Density: [-0.65023423 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.95726122 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.95726122\n",
      " -0.95726122 -0.95726122]\n",
      "Class: no, Feature: age_>40, Density: [-0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.95726122]\n",
      "Class: no, Feature: income_high, Density: [-0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.65023423 -0.65023423 -0.65023423 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: no, Feature: income_low, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -0.41566086 -0.41566086 -0.41566086\n",
      " -0.41566086 -0.41566086]\n",
      "Class: no, Feature: income_medium, Density: [-0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.65023423 -0.95726122]\n",
      "Class: no, Feature: student_no, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -1.40257636 -1.40257636 -0.41566086\n",
      " -1.40257636 -0.41566086]\n",
      "Class: no, Feature: student_yes, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -1.40257636 -1.40257636 -0.41566086\n",
      " -1.40257636 -0.41566086]\n",
      "Class: no, Feature: credit_rating_excellent, Density: [-0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: no, Feature: credit_rating_fair, Density: [-0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: yes, Feature: age_31...40, Density: [-0.71077938 -0.71077938 -0.88042824 -0.71077938 -0.71077938 -0.71077938\n",
      " -0.88042824 -0.71077938 -0.71077938 -0.71077938 -0.71077938 -0.88042824\n",
      " -0.88042824 -0.71077938]\n",
      "Class: yes, Feature: age_<=30, Density: [-1.34211049 -1.34211049 -0.43916741 -0.43916741 -0.43916741 -0.43916741\n",
      " -0.43916741 -1.34211049 -1.34211049 -0.43916741 -1.34211049 -0.43916741\n",
      " -0.43916741 -0.43916741]\n",
      "Class: yes, Feature: age_>40, Density: [-0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888 -1.08485888\n",
      " -0.56577997 -0.56577997 -0.56577997 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: income_high, Density: [-1.34211049 -1.34211049 -1.34211049 -0.43916741 -0.43916741 -0.43916741\n",
      " -0.43916741 -0.43916741 -0.43916741 -0.43916741 -0.43916741 -0.43916741\n",
      " -1.34211049 -0.43916741]\n",
      "Class: yes, Feature: income_low, Density: [-0.56577997 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -1.08485888 -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997\n",
      " -0.56577997 -0.56577997]\n",
      "Class: yes, Feature: income_medium, Density: [-0.71077938 -0.71077938 -0.71077938 -0.88042824 -0.71077938 -0.71077938\n",
      " -0.71077938 -0.88042824 -0.71077938 -0.88042824 -0.88042824 -0.88042824\n",
      " -0.71077938 -0.88042824]\n",
      "Class: yes, Feature: student_no, Density: [-1.08485888 -1.08485888 -1.08485888 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: student_yes, Density: [-1.08485888 -1.08485888 -1.08485888 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: credit_rating_excellent, Density: [-0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: credit_rating_fair, Density: [-0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "\n",
      "Features and Classes with Zero Densities:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#A2\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Data from CSV file\n",
    "df = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# features and target variable\n",
    "features = df[['age', 'income', 'student', 'credit_rating']]\n",
    "target = df['buys_computer']\n",
    "\n",
    "# Encode categorical variables\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Dictionary to store class conditional densities\n",
    "class_conditional_densities = {}\n",
    "\n",
    "# Calculating class conditional densities for each feature\n",
    "for class_label in target.unique():\n",
    "    # Select instances for the current class\n",
    "    instances = features_encoded[target == class_label]\n",
    "    \n",
    "    # Calculating kernel density estimate for each feature\n",
    "    for feature in features_encoded.columns:\n",
    "        kde = KernelDensity(bandwidth=0.5)  # You may need to adjust the bandwidth\n",
    "        kde.fit(instances[[feature]])\n",
    "        class_conditional_densities[(class_label, feature)] = kde\n",
    "\n",
    "# Display the class conditional densities\n",
    "for key, kde in class_conditional_densities.items():\n",
    "    print(f\"Class: {key[0]}, Feature: {key[1]}, Density: {kde.score_samples(features_encoded[[key[1]]])}\")\n",
    "\n",
    "# Checking for zero values\n",
    "zero_densities = [(class_label, feature) for (class_label, feature), kde in class_conditional_densities.items()\n",
    "                  if any(density == float('-inf') for density in kde.score_samples(features_encoded[[feature]]))]\n",
    "\n",
    "# Display features and classes with zero densities\n",
    "print(\"\\nFeatures and Classes with Zero Densities:\")\n",
    "print(zero_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98923d9e-b2df-418d-a78f-7263afd3e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 12.95\n",
      "p-value: 0.6764100579553458\n",
      "The features are independent (fail to reject the null hypothesis)\n"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Data from CSV file\n",
    "df = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Select the relevant features\n",
    "features = df[['age', 'income', 'student', 'credit_rating']]\n",
    "\n",
    "# Creating a contingency table\n",
    "contingency_table = pd.crosstab(features['age'], [features['income'], features['student'], features['credit_rating']])\n",
    "\n",
    "# Perform the chi-square test of independence\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "\n",
    "# Checking for significance\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"The features are not independent (reject the null hypothesis)\")\n",
    "else:\n",
    "    print(\"The features are independent (fail to reject the null hypothesis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2e05f6d-7f91-45cf-b091-f4dc90c31f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "#A4\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Data from CSV file\n",
    "df = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df[['age', 'income', 'student', 'credit_rating']]\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.apply(label_encoder.fit_transform)\n",
    "\n",
    "# One-hot encode the categorical features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X_encoded).toarray()\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the Gaussian Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier \n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6005dbfa-9218-4ca9-b1d2-db5e389ad75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.43      0.14        49\n",
      "           1       0.00      0.00      0.00        44\n",
      "           2       0.14      0.02      0.03        51\n",
      "           3       0.07      0.38      0.12        47\n",
      "           4       0.00      0.00      0.00        39\n",
      "           5       0.00      0.00      0.00        59\n",
      "           6       0.00      0.00      0.00        64\n",
      "           7       0.00      0.00      0.00        47\n",
      "           8       0.00      0.00      0.00        55\n",
      "           9       0.09      0.21      0.13        56\n",
      "          10       0.11      0.06      0.07        53\n",
      "          11       0.07      0.17      0.10        42\n",
      "          12       0.04      0.22      0.06        45\n",
      "          13       0.00      0.00      0.00        42\n",
      "          14       0.02      0.02      0.02        45\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.00      0.00      0.00        49\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.00      0.00      0.00        49\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.04      0.07      0.05        55\n",
      "          21       0.00      0.00      0.00        51\n",
      "          22       0.00      0.00      0.00        47\n",
      "          23       0.00      0.00      0.00        58\n",
      "          24       0.04      0.04      0.04        51\n",
      "          25       0.00      0.00      0.00        62\n",
      "          26       0.00      0.00      0.00        39\n",
      "          27       0.00      0.00      0.00        45\n",
      "          28       0.06      0.17      0.08        54\n",
      "          29       0.00      0.00      0.00        44\n",
      "          30       0.00      0.00      0.00        52\n",
      "          31       0.06      0.15      0.08        55\n",
      "          32       0.10      0.21      0.13        52\n",
      "          33       0.00      0.00      0.00        56\n",
      "          34       0.03      0.07      0.04        44\n",
      "          35       0.00      0.00      0.00        57\n",
      "          36       0.01      0.03      0.02        40\n",
      "          37       0.03      0.02      0.02        52\n",
      "          38       0.14      0.15      0.14        48\n",
      "          39       0.02      0.02      0.02        42\n",
      "          40       0.00      0.00      0.00        50\n",
      "          41       0.04      0.05      0.04        43\n",
      "\n",
      "    accuracy                           0.06      2100\n",
      "   macro avg       0.03      0.06      0.03      2100\n",
      "weighted avg       0.03      0.06      0.03      2100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#A5\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Data from CSV file\n",
    "df = pd.read_csv('the_final_no_changes_data.csv')\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df[['polarity', 'subjectivity', 'len']]\n",
    "y = df['category']\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Gaussian Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612b064-ce93-48e9-85ef-4c93f83947fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
